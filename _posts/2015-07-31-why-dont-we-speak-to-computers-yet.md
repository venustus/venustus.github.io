---
layout: post
title: Why don't we speak to computers yet?
date: '2015-06-27T18:50:00.000-08:00'
author: Venkat Pedapati
tags: evolution
modified_time: '2015-06-027T18:50:00.000-08:00'
---

Every day, I drive through 15 kilometers of Bangalore traffic to commute to Office and it turns out to be the most 
boring part of my day. It is not as bad as it can be, since most of it is uninterrupted highway and I have my trusty
iphone to spend time on, while I'm waiting for the signal to turn green. I usually read through my tweet timeline
or flip through Flipboard articles. 

But I hardly get time to read one article completely. The breaks are too quick to complete an article. I end up 
disappointed. These days, strangely, I want that signal to turn red before I cross, so I get those extra 2 minutes
to finish my article. While this part of my day is otherwise pretty boring, it is the only time of the day I 
allocated myself to read and catch up on my tech news appetite.

Being a programmer myself, I kept wondering if I could create a tool that can read my stuff aloud for me while I am
driving. But a dumb screen reader is the least I would want at this point. Since that would mean I have to still navigate
between different screens myself and there would be no way to stop it or fast forward.

What I wanted is a more intelligent voice assistant which can understand what I speak and then respond to them accordingly.
Well, Apple Siri or Google Now (and now, Cortana), almost immediately come to mind when thinking of intelligent voice assistants.
Yes, Siri is amazing. It has some beautiful voices, and it can understand some things which I would treat as insanely 
complex for a computer. It even has some humour. But unfortunately, all the three assistants are limited to only certain
predefined functions and they have to be programmed/upgraded to perform a new function. For example, Siri can't read my 
 tweets or facebook posts for me. Nor can it read me any articles (at least in a useful manner).
 
I sense that a common framework for human-computer voice interaction is missing from this world today. While it is reasonably
easier to make a particular app/website voice interactive by using existing technologies, not many people are doing it. 
I doubt this is because of lack of a common framework for voice interaction, coupled with the opinion that these kind of 
features are for very niche customers. 

It is true that with existing technologies, it is tough to get very far. We can get computers to read out facebook 
posts and tweets for us, but how to deal with unstructured content? For example, how to make our computers read out an 
article from a website. Web, today is largely unorganized and there is no common structure to web pages. There have been
some recent advances like HTML5 <article> tags that make life easier, but there is still a long way to go before all browsers
adopt such common standards. Even if one could identify the article from a page, it is far from read-able since there is lot
more inside the article that can't be read - like images or advertisements etc.

It is clear that web hasn't evolved keeping voice interaction in mind. In fact, extracting content from a HTML web page is
an active area of machine learning research today. I've been working on a tool/framework that makes it easy for apps/websites
to make themselves voice-interactive and I'll share the specifics in another blog post.

In the meanwhile, I'll keep wondering about the all-intelligent voice assistant that can understand me. There is no shortage 
of them in science fiction. My favorites are the Jarvis from Iron Man franchise and <i>Samantha</i> from <i>Her</i>. 
I'll leave you with this clip featuring <i>Samantha</i> from the movie <i>Her</i>.

<iframe width="560" height="315" src="https://www.youtube.com/embed/n1AjtIAje3o" frameborder="0" allowfullscreen></iframe>


